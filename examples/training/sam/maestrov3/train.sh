python -m perceiver.scripts.audio.symbolic fit \
  --model.activation_checkpointing=true \
  --model.num_channels=512 \
  --model.num_self_attention_layers=8 \
  --model.num_heads=8 \
  --model.max_latents=1024 \
  --model.cross_attention_dropout=0.1 \
  --model.post_attention_dropout=0.1 \
  --model.residual_dropout=0.1 \
  --data=MaestroV3DataModule \
  --data.max_seq_len=2048 \
  --data.batch_size=48 \
  --data.padding_side=left \
  --data.num_workers=1 \
  --optimizer=AdamW \
  --optimizer.weight_decay=0.01 \
  --optimizer.lr=2e-4 \
  --lr_scheduler.warmup_steps=200 \
  --trainer.max_steps=20000 \
  --trainer.accelerator=gpu \
  --trainer.devices=2 \
  --trainer.val_check_interval=0.5 \
  --trainer.gradient_clip_val=0.5 \
  --trainer.accumulate_grad_batches=2 \
  --trainer.logger=TensorBoardLogger \
  --trainer.log_every_n_steps=20 \
  --trainer.logger.save_dir=logs \
  --trainer.logger.name=sam
